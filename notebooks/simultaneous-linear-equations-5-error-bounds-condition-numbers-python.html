
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>26. Simultaneous Linear Equations, Part 5: Error bounds for linear algebra, condition numbers, matrix norms, etc. &#8212; Elementary Numerical Analysis (with Python)</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="27. Simultaneous Linear Equations, Part 6: Iterative Methods" href="simultaneous-linear-equations-6-iterative-methods.html" />
    <link rel="prev" title="25. Initial Value Problems for Ordinary Differential Equations, Part 5: Error Control and Variable Step Sizes" href="ODE-IVP-5-error-control-python.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/UNC_BearMascot.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Elementary Numerical Analysis (with Python)</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../preface.html">
   Elementary Numerical Analysis with Python
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Frontmatter
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../references.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../plans-for-expansion-improvement.html">
   Full Disclosure: Things I Plan to do to Expand and Improve This Book
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Numerical Analysis
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="root-finding-by-interval-halving-python.html">
   1. Root Finding by Interval Halving (Bisection)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fixed-point-iteration-python.html">
   2. Solving Equations by Fixed Point Iteration (of Contraction Mappings)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="newtons-method-python.html">
   3. Newton’s Method for Solving Equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="taylors-theorem.html">
   4. Taylor’s Theorem and the Accuracy of Linearization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="error-measures-convergence-rates.html">
   5. Measures of Error and Order of Convergence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="newtons-method-convergence-rate.html">
   6. The Convergence Rate of Newton’s Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="root-finding-without-derivatives-python.html">
   7. Root-finding Without Derivatives
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="simultaneous-linear-equations-1-row-reduction-python.html">
   8. Simultaneous Linear Equations, Part 1: Row Reduction/Gaussian Elimination
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="machine-numbers-rounding-error-and-error-propagation-python.html">
   9. Machine Numbers, Rounding Error and Error Propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="simultaneous-linear-equations-2-pivoting-python.html">
   10. Simultaneous Linear Equations, Part 2: Partial Pivoting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="simultaneous-linear-equations-3-lu-factorization-python.html">
   11. Simultaneous Linear Equations, Part 3: Solving
   <span class="math notranslate nohighlight">
    \(Ax = b\)
   </span>
   with LU factorization,
   <span class="math notranslate nohighlight">
    \(A = L U\)
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="simultaneous-linear-equations-4-plu-factorization-python.html">
   12. Simultaneous Linear Equations, Part 4: Solving
   <span class="math notranslate nohighlight">
    \(Ax = b\)
   </span>
   With Both Pivoting and LU factorization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="polynomial-collocation%2Bapproximation-python.html">
   13. Polynomial Collocation (Interpolation/Extrapolation) and Approximation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="polynomial-collocation-error-formulas-python.html">
   14. Error Formulas for Polynomial Collocation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="derivatives-and-the-method-of-undetermined-coefficents.html">
   15. Approximating Derivatives by the Method of Undetermined Coefficients
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="richardson-extrapolation.html">
   16. Richardson Extrapolation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="definite-integrals-1-building-blocks-python.html">
   17. Definite Integrals, Part 1: The Building Blocks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="definite-integrals-2-composite-rules.html">
   18. Definite Integrals, Part 2: The Composite Trapezoid and Midpoint Rules
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="definite-integrals-3-simpson-richardson.html">
   19. Definite Integrals, Part 3: The (Composite) Simpson’s Rule and Richardson Extrapolation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="definite-integrals-4-romberg-integration.html">
   20. Definite Integrals, Part 4: Romberg Integration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ODE-IVP-1-basics-and-Euler-python.html">
   21. Initial Value Problems for Ordinary Differential Equations, Part 1: Basic Concepts and Euler’s Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ODE-IVP-2-Runge-Kutta-python.html">
   22. Initial Value Problems for ODEs, Part 2: Runge-Kutta Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ODE-IVP-3-error-results-one-step-methods.html">
   23. Initial Value Problems for Ordinary Differential Equations, Part 3: Global Error Bounds for One Step Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ODE-IVP-4-system-higher-order-equations.html">
   24. Initial Value Problems for Ordinary Differential Equations, Part 4: Systems of ODEs and Higher Order ODEs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ODE-IVP-5-error-control-python.html">
   25. Initial Value Problems for Ordinary Differential Equations, Part 5: Error Control and Variable Step Sizes
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   26. Simultaneous Linear Equations, Part 5: Error bounds for linear algebra, condition numbers, matrix norms, etc.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="simultaneous-linear-equations-6-iterative-methods.html">
   27. Simultaneous Linear Equations, Part 6: Iterative Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="minimization-1D.html">
   28. Finding the Minimum of a Function of One Variable Without Using Derivatives — A Brief Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="eigenproblems.html">
   29. Computing Eigenvalues and Eigenvectors: the Power Method, and a bit beyond
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../future_topics.html">
   30. Some Future Topics
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Preliminary Versions of Some Possible Future Sections
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="newtons-method-for-systems-introduction.html">
   1. Solving system of nonlinear equations by generalizations of Newton’s method; A Brief Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="simultaneous-linear-equations-7-tridiagonal-banded-and-SDD-matrices-preliminary.html">
   2. Simultaneous Linear Equations, Part 7: Faster Methods for Solving
   <span class="math notranslate nohighlight">
    \(Ax = b\)
   </span>
   for Tridiagonal and Banded matrices, and Strict Diagonal Dominance
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="root-finding-by-interval-halving-exercises-python.html">
   Exercises on the Bisection Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fixed-point-iteration-exercises.html">
   Exercises on Fixed Point Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="error-measures-convergence-rates-exercises.html">
   Exercises on Error Measures and Convergence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="newtons-method-exercises.html">
   Exercises on Newton’s Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="root-finding-without-derivatives-exercises.html">
   Exercises on Root-finding Without Derivatives
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="machine-numbers-rounding-error-and-error-propagation-exercises.html">
   Exercises on Machine Numbers, Rounding Error and Error Propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="simultaneous-linear-equations-exercises.html">
   Exercises on Solving Simultaneous Linear Equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="derivatives-and-the-method-of-undetermined-coefficents-exercises.html">
   Exercises on Approximating Derivatives, the Method of Undetermined Coefficients and Richardson Extrapolation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ODE-IVP-exercises.html">
   Exercises on Initial Value Problems for Ordinary Differential Equations
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Assignments
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="assignment1.html">
   MATH 375 Assignment 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="assignment2.html">
   MATH 375 Assignment 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="assignment3.html">
   MATH 375 Assignment 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="root_finding.html">
   Module root_finding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="assignment4.html">
   MATH 375 Assignment 4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="assignment5.html">
   MATH 375 Assignment 5
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Project on Numerical Calculus
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../project-on-numerical-calculus/introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../project-on-numerical-calculus/task-1-and-2-centered-difference-derivative-approximation-and-richardson.html">
   Centered Difference Approximation of the Derivative
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../project-on-numerical-calculus/task-1-and-2-centered-difference-derivative-approximation-and-richardson.html#improving-on-the-centered-difference-approximation-with-richardson-extrapolation">
   Improving on the Centered Difference Approximation with Richardson Extrapolation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../project-on-numerical-calculus/task-3-composite-trapezoid-rule.html">
   The Composite Trapezoid Rule (and Composite Midpoint Rule)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../project-on-numerical-calculus/task-4-recursive-trapezoid-rule.html">
   The Recursive Trapezoid Rule, with error control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../project-on-numerical-calculus/task-5-and-6-modified-trapezoid-method.html">
   The Modified Trapezoid Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../project-on-numerical-calculus/task-7-romberg-method.html">
   The Romberg Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../project-on-numerical-calculus/test-cases-differentiation.html">
   Test Cases for Differentiation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../project-on-numerical-calculus/test-cases-integration.html">
   Test Cases for Integration
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Some Final Project Possibilities
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html">
   Some Final Project Possibilites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html#minimizing-functions-of-one-and-several-variables">
   Minimizing Functions of One and Several Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html#root-finding-by-repeated-inverse-quadratic-approximation-with-bracketing">
   Root-finding by Repeated Inverse Quadratic Approximation with Bracketing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html#a-more-reliable-secant-method">
   A More Reliable Secant Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html#computing-eigenvalues-and-eigenvectors">
   Computing Eigenvalues and Eigenvectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html#iterative-methods-for-solving-simultaneous-linear-equations-ax-b">
   Iterative Methods for Solving Simultaneous Linear Equations,
   <span class="math notranslate nohighlight">
    \(Ax = b\)
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html#solving-simultaneous-nonlinear-equations">
   Solving Simultaneous Nonlinear Equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html#fitting-smooth-piecewise-cubic-functions-to-data">
   Fitting Smooth Piecewise Cubic Functions to Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html#least-squares-fitting-to-data-and-functions">
   Least-Squares Fitting to Data and Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="project-possibilities.html#boundary-value-problems-for-differential-equations">
   Boundary Value Problems for Differential Equations
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Python and Jupyter Notebook Review (with Numpy and Matplotlib)
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/introduction.html">
   1. Introduction to
   <em>
    Python Preview
   </em>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/getting-python-software-for-scientific-computing.html">
   2. Getting Python Software for Scientific Computing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/suggestions-on-python-and-notebook-usage.html">
   3. Suggestions and Notes on Python and Jupyter Notebook Usage
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/python-variables-lists-tuples-numpy-arrays.html">
   4. Python Variables, Including Lists and Tuples, and Arrays from Package Numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/functions.html">
   5. Defining and Using Python Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/decisions-with-if-else-elif.html">
   6. Decision Making With if, else, and elif
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/iteration-with-for.html">
   7. Iteration with
   <code class="docutils literal notranslate">
    <span class="pre">
     for
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/iteration-with-while.html">
   8. Iteration with
   <code class="docutils literal notranslate">
    <span class="pre">
     while
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/code-files-modules-IDEs.html">
   9. Code Files, Modules, and an Integrated Development Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/recursion.html">
   10. Recursion (vs iteration)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/graphing-with-matplotlib.html">
   11. Plotting Graphs with Matplotlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/array-operations-and-linear-algebra.html">
   12. Numpy Array Operations and Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/scipy-tools-for-linear-algebra.html">
   13. Package Scipy and More Tools for Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/summation-and-integration.html">
   14. Summation and Integration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/random-numbers-and-simulation.html">
   15. Random Numbers, Histograms, and a Simulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/formatted-output-and-some-text-string-manipulation.html">
   16. Formatted Output and Some Text String Manipulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/classes-objects-attributes-methods.html">
   17. Classes, Objects, Attributes, Methods: Very Basic Object-Oriented Programming in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_tutorial/exception-handling.html">
   18. Exceptions and Exception Handling
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="numerical_methods_module.html">
   Notebook for generating the module
   <code class="docutils literal notranslate">
    <span class="pre">
     numerical_methods_module
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear-algebra-with-0-based-indexing-and-semiopen-intervals.html">
   Linear algebra algorithms using 0-based indexing and semi-open intervals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="sample-project-newtons-method-python-draft.html">
   Numerical Analysis Sample Project on Newtons’s Method
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/simultaneous-linear-equations-5-error-bounds-condition-numbers-python.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/notebooks/simultaneous-linear-equations-5-error-bounds-condition-numbers-python.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#residuals-backward-errors-forward-errors-and-condition-numbers">
   26.1. Residuals, backward errors, forward errors, and condition numbers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-norms-induced-by-vector-norms">
   26.2. Matrix norms induced by vector norms
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#properties-of-induced-matrix-norms">
   26.3. Properties of (induced) matrix norms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-note-numpy-linalg-norm">
     26.3.1. Python Note:
     <code class="docutils literal notranslate">
      <span class="pre">
       numpy.linalg.norm
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#relative-error-bound-and-condition-number">
   26.4. Relative error bound and condition number
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aside-estimating-a-1-infty-and-thence-the-condition-number-and-numpy-linalg-cond">
     26.4.1. Aside: estimating
     <span class="math notranslate nohighlight">
      \(\|A^{-1}\|_\infty\)
     </span>
     and thence the condition number, and
     <code class="docutils literal notranslate">
      <span class="pre">
       numpy.linalg.cond
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#well-conditioned-and-ill-conditioned-problems-and-matrices">
   26.5. Well-conditioned and ill-conditioned problems and matrices
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#an-important-example-the-hilbert-matrices">
   26.6. An important example: the Hilbert matrices
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="simultaneous-linear-equations-part-5-error-bounds-for-linear-algebra-condition-numbers-matrix-norms-etc">
<h1><span class="section-number">26. </span>Simultaneous Linear Equations, Part 5: Error bounds for linear algebra, condition numbers, matrix norms, etc.<a class="headerlink" href="#simultaneous-linear-equations-part-5-error-bounds-for-linear-algebra-condition-numbers-matrix-norms-etc" title="Permalink to this headline">¶</a></h1>
<p><strong>Version of April 13, 2021</strong></p>
<p><strong>Brenton LeMesurier</strong></p>
<p>University of Northern Colorado, Greeley, Colorado in Spring 2021,
<a class="reference external" href="mailto:brenton&#46;lemesurier&#37;&#52;&#48;unco&#46;edu">brenton<span>&#46;</span>lemesurier<span>&#64;</span>unco<span>&#46;</span>edu</a>;
<br>
More permanent address: The College of Charleston, Charleston, South Carolina,
<a class="reference external" href="mailto:lemesurierb&#37;&#52;&#48;cofc&#46;edu">lemesurierb<span>&#64;</span>cofc<span>&#46;</span>edu</a></p>
<p><strong>References:</strong></p>
<ul class="simple">
<li><p>Section 2.3.1 <em>Error Magnification and Condition Number</em> of <a class="reference external" href="../references.html#Sauer">Sauer</a></p></li>
<li><p>Section 7.5 <em>Error Bounds and Iterative Refinement</em> of <a class="reference external" href="../references.html#Burden-Faires">Burden&amp;Faires</a> — but the last part, on <em>Iterative Refinement</em>, is not relevant here.</p></li>
<li><p>Section 8.4 of <a class="reference external" href="../references.html#Chenney-Kincaid">Chenney&amp;Kincaid</a></p></li>
</ul>
<div class="section" id="residuals-backward-errors-forward-errors-and-condition-numbers">
<h2><span class="section-number">26.1. </span>Residuals, backward errors, forward errors, and condition numbers<a class="headerlink" href="#residuals-backward-errors-forward-errors-and-condition-numbers" title="Permalink to this headline">¶</a></h2>
<p>For an approximation <span class="math notranslate nohighlight">\(x_a\)</span> of the solution <span class="math notranslate nohighlight">\(x\)</span> of <span class="math notranslate nohighlight">\(A x = b\)</span>, the <em>residual</em> <span class="math notranslate nohighlight">\(r = A x_a - b\)</span> measures error as <em>backward error</em>, often measured by a single number, the <em>residual norm</em> <span class="math notranslate nohighlight">\(\| A x_a - b \|\)</span>.
Any norm could be used, but the maximum norm is usualt preferred, for reasons that we will see soon.</p>
<p>The corresponding (dimensionless) measure of relative error is defined as</p>
<div class="math notranslate nohighlight">
\[\frac{\|r\|}{\|b\|}.\]</div>
<p>However, these can greatly underestimate the <em>forward</em> errors in the solution: the absolute error <span class="math notranslate nohighlight">\(\|x - x_a\|\)</span> and relative error</p>
<div class="math notranslate nohighlight">
\[Rel(x_a) = \frac{\|x - x_a\|}{\| x \|}\]</div>
<p>To relate these to the residual, we need the concepts of a <em>matrix norm</em> and the <em>condition number</em> of a matrix.</p>
<p><a name="matrix-norms"></a></p>
</div>
<div class="section" id="matrix-norms-induced-by-vector-norms">
<h2><span class="section-number">26.2. </span>Matrix norms induced by vector norms<a class="headerlink" href="#matrix-norms-induced-by-vector-norms" title="Permalink to this headline">¶</a></h2>
<p>Given any vector norm <span class="math notranslate nohighlight">\(\| \cdot \|\)</span> — such as the maximum (“infinity”) norm <span class="math notranslate nohighlight">\(\| \cdot \|_\infty\)</span> or the Euclidean norm (length) <span class="math notranslate nohighlight">\(\| \cdot \|_2\)</span> — the correponding <em>induced matrix norm</em> is</p>
<div class="math notranslate nohighlight">
\[
\| A \| := \max_{x \neq 0} \frac{\| Ax \|}{\| x \|}, =  \max_{\|x\|=1} \| Ax \|
\]</div>
<p>This maximum exists for ethe rof these vector norms, and for the infinity norm there ia an explicit formula for it:
for any <span class="math notranslate nohighlight">\(m\times n\)</span> matrix,</p>
<div class="math notranslate nohighlight">
\[
\|A\|_\infty = \max_{i=1}^m \sum_{j=1}^n |a_{ij}|
\]</div>
<p>(On the other hand, it is far harder to compute the Euclidean norm of a matrix: the formula requires computing eigenvalues.)</p>
<p>Note that when the matrix is a vector considered as a matrix with a single column — so <span class="math notranslate nohighlight">\(n=1\)</span> — the sum goes away, and this agrees with the infinity vector norm.
This allows us to consider vectors as being just matrices with a single column, which we will often do from now on.</p>
</div>
<div class="section" id="properties-of-induced-matrix-norms">
<h2><span class="section-number">26.3. </span>Properties of (induced) matrix norms<a class="headerlink" href="#properties-of-induced-matrix-norms" title="Permalink to this headline">¶</a></h2>
<p>These induced matrix norms have many properties in common with Euclidean length and other vector norms, but there can also be products, and then one has to be careful.</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(\|A\| \geq 0\)</span> (positivity)</p></li>
<li><p><span class="math notranslate nohighlight">\(\| A \| = 0\)</span> if and only if <span class="math notranslate nohighlight">\(A = 0\)</span> (definiteness)</p></li>
<li><p><span class="math notranslate nohighlight">\(\| c A \| = |c| \, \|A\|\)</span> for any constant <span class="math notranslate nohighlight">\(c\)</span> (absolute homogeneity)</p></li>
<li><p><span class="math notranslate nohighlight">\(\| A + B \| \leq \| A \| + \| B \|\)</span> (sub-additivity or the triangle inequality),
<br>
and when the product of two matrices makes sense (including matrix-vector products),</p></li>
<li><p><span class="math notranslate nohighlight">\(\| A B \| \leq \| A \| \, \| B \|\)</span> (sub-multiplicativity)</p></li>
</ol>
<p>Note the failure to always have equality with products.
Indeed one can have <span class="math notranslate nohighlight">\(A B = 0\)</span> with <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> both non-zero, such as when <span class="math notranslate nohighlight">\(A\)</span> is a singular matrix and <span class="math notranslate nohighlight">\(B\)</span> is a null-vector for it.</p>
<p><strong>Aside:</strong> There are other matrix norms of use in some contexts, in particular the
<a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm">Frobenius norm</a>.
Then the above properties are often used to <em>define</em> what it is to be a matrix form, much as the the first four define what it is to be a vector norm.</p>
<div class="section" id="python-note-numpy-linalg-norm">
<h3><span class="section-number">26.3.1. </span>Python Note: <code class="docutils literal notranslate"><span class="pre">numpy.linalg.norm</span></code><a class="headerlink" href="#python-note-numpy-linalg-norm" title="Permalink to this headline">¶</a></h3>
<p>Python package Numpy provides the function <code class="docutils literal notranslate"><span class="pre">numpy.linalg.norm</span></code> for evaluating matrix norms.
The default usage <code class="docutils literal notranslate"><span class="pre">numpy.linalg.norm(A)</span></code> computes <span class="math notranslate nohighlight">\(\| A \|_2\)</span>, which one can also specify explicitly with <code class="docutils literal notranslate"><span class="pre">numpy.linalg.norm(A,</span> <span class="pre">2)</span></code>;
to get the maximum norm <span class="math notranslate nohighlight">\(\| A \|_\infty\)</span>, one uses <code class="docutils literal notranslate"><span class="pre">numpy.linalg.norm(A,</span> <span class="pre">numpy.inf)</span></code>.</p>
</div>
</div>
<div class="section" id="relative-error-bound-and-condition-number">
<h2><span class="section-number">26.4. </span>Relative error bound and condition number<a class="headerlink" href="#relative-error-bound-and-condition-number" title="Permalink to this headline">¶</a></h2>
<p>It can be proven that, for any choice of norm,</p>
<div class="math notranslate nohighlight">
\[\text{Rel}(x_a) = \frac{\|x - x_a\|}{\| x \|} \leq \|A\|\|A^{-1}\| \frac{\|r\|}{\|b\|},\]</div>
<p>where the last factor <span class="math notranslate nohighlight">\(\displaystyle \frac{\|r\|}{\|b\|}\)</span> is the <em>relative backward error</em>.</p>
<p>Since we can (though often with considerable effort, due to the inverse!) compute the right-hand side when the infinity norm is used, we can compute an upper bound on the relative error.
From this, an upper bound on the absolute error can be computed if needed.</p>
<p>The <em>growth factor</em> between the relative backward error measured by the residual and the relative (forward) error is called the <em>condition number</em>, <span class="math notranslate nohighlight">\(K(A)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\kappa(A) := \|A\| \|A^{-1}\|\]</div>
<p>so that the above bound on the relative error can be restated as</p>
<div class="math notranslate nohighlight">
\[\text{Rel}(x_a) = \frac{\|x - x_a\|}{\| x \|} \leq \kappa(A) \frac{\|r\|}{\|b\|}\]</div>
<p>Actually there is a different condition number for each choice of norm; we work with</p>
<div class="math notranslate nohighlight">
\[\kappa_\infty(A) := \|A\|_\infty \|A^{-1}\|_\infty\]</div>
<p>Note that for a singular matrix, this is undefined: we can intuitively say that the condition number is then infinite.
<br>
At the other extreme, the identity matrix <span class="math notranslate nohighlight">\(I\)</span> has norm 1 and condition number 1 (using any norm), and this is the best possible because in general <span class="math notranslate nohighlight">\(\kappa(A) \geq 1\)</span>. (This follows from property 5, sub-multiplicativity.)</p>
<div class="section" id="aside-estimating-a-1-infty-and-thence-the-condition-number-and-numpy-linalg-cond">
<h3><span class="section-number">26.4.1. </span>Aside: estimating <span class="math notranslate nohighlight">\(\|A^{-1}\|_\infty\)</span> and thence the condition number, and  <code class="docutils literal notranslate"><span class="pre">numpy.linalg.cond</span></code><a class="headerlink" href="#aside-estimating-a-1-infty-and-thence-the-condition-number-and-numpy-linalg-cond" title="Permalink to this headline">¶</a></h3>
<p>In Python, good approximations of condition numbers are given by the function <code class="docutils literal notranslate"><span class="pre">numpy.linalg.cond</span></code>.
<br>
As with <code class="docutils literal notranslate"><span class="pre">numpy.linalg.norm</span></code>, the default <code class="docutils literal notranslate"><span class="pre">numpy.linalg.cond(A)</span></code> gives <span class="math notranslate nohighlight">\(\kappa_2(A)\)</span>, based on the Euclidian length <span class="math notranslate nohighlight">\(\| \cdot \|_2\)</span> for vectors;
to get the infinity norm version <span class="math notranslate nohighlight">\(\kappa_\infty(A)\)</span> use <code class="docutils literal notranslate"><span class="pre">numpy.linalg.cond(A,</span> <span class="pre">numpy.inf)</span></code>.</p>
<p>This is not done exactly, since computing the inverse is a lot of work for large matrices, and good estimates can be got far more quickly.
The basic idea is start with the formula</p>
<div class="math notranslate nohighlight">
\[\| A^{-1} \| = \max_{\|x\|=1} \| A ^{-1} x \|\]</div>
<p>and instead compute the maximum over some finite selection of values for <span class="math notranslate nohighlight">\(x\)</span>: call them <span class="math notranslate nohighlight">\(x^{(k)}\)</span>.
Then to evaluate <span class="math notranslate nohighlight">\(y^{(k)} =  A ^{-1} x^{(k)}\)</span>, express this through the equation <span class="math notranslate nohighlight">\(A y^{(k)} = x^{(k)}\)</span>.
Once we have an LU factorization for <span class="math notranslate nohighlight">\(A\)</span> (which one probably would have when exploring errors in a numerical solution of <span class="math notranslate nohighlight">\(Ax = b\)</span>) each of these systems can be solved relatively fast:
Then</p>
<div class="math notranslate nohighlight">
\[\| A^{-1} \| \approx \max_k \| y^{(k)} \|.\]</div>
</div>
</div>
<div class="section" id="well-conditioned-and-ill-conditioned-problems-and-matrices">
<h2><span class="section-number">26.5. </span>Well-conditioned and ill-conditioned problems and matrices<a class="headerlink" href="#well-conditioned-and-ill-conditioned-problems-and-matrices" title="Permalink to this headline">¶</a></h2>
<p>Condition numbers, giving upper limit on the ratio of forward error to backward error,
measure the amplification of errors, and have counterparts in other contexts.
For example, with an approximation <span class="math notranslate nohighlight">\(r_a\)</span> of a root <span class="math notranslate nohighlight">\(r\)</span> of the equation <span class="math notranslate nohighlight">\(f(x) = 0\)</span>, the ratio of forward error to backward error is bounded by
<span class="math notranslate nohighlight">\(\displaystyle \max 1/| f'(x) | = \frac{1}{\min | f'(x) |}\)</span>, where the maximum only need be taken over an interval known to contain both the root and the approximation.
This condition number becomes “infinite” for a multiple root, <span class="math notranslate nohighlight">\(f'(r) = 0\)</span>, related to the problems we have seen in that case.</p>
<p>Careful calculation of an approximate solution <span class="math notranslate nohighlight">\(x_a\)</span> of <span class="math notranslate nohighlight">\(Ax = b\)</span> can often get a <em>residual</em> that is at the level of machine rounding error, so that roughly the relative backward error is of size comparable to the machine unit, <span class="math notranslate nohighlight">\(u\)</span>.
The condition number then guarantees that the (forward) relative error is no greater than about <span class="math notranslate nohighlight">\(u \, \kappa(A)\)</span>.</p>
<p>In terms of significant bits, with <span class="math notranslate nohighlight">\(p\)</span> bit machine arithmetic, one can hope to get <span class="math notranslate nohighlight">\(p - \log_2(\kappa(A))\)</span> significant bits in the result, but can not rely on more, so one loses <span class="math notranslate nohighlight">\(\log_2(\kappa(A))\)</span> significant bits.
Compare this to the observation that one can expect to lose at least <span class="math notranslate nohighlight">\(p/2\)</span> significant bits when using the approximation <span class="math notranslate nohighlight">\(Df(x) \approx D_hf(x) - (f(x+h) = f(x))/h\)</span>.</p>
<p>A <strong>well-conditioned problem</strong> is one that is not too highly sensitive to errors in rounding or input data; for an eqution <span class="math notranslate nohighlight">\(Ax = b\)</span>, this corresponds to the condition number of <span class="math notranslate nohighlight">\(A\)</span> not being to large; the matrix <span class="math notranslate nohighlight">\(A\)</span> is then sometimes also called well-conditioned.
This is of course vague, but might typically mean that <span class="math notranslate nohighlight">\(p - \log_2(\kappa(A))\)</span> is a sufficient number of significant bits for a particular purpose.</p>
<p>A problem that is not deemed well-conditioned is called <strong>ill-conditioned</strong>, so that a matrix of uncomfortably large condition number is also sometimes called ill-conditioned.
An ill-conditioned problem might still be well-posed, but just requiring careful and precise solution methods.</p>
</div>
<div class="section" id="an-important-example-the-hilbert-matrices">
<h2><span class="section-number">26.6. </span>An important example: the Hilbert matrices<a class="headerlink" href="#an-important-example-the-hilbert-matrices" title="Permalink to this headline">¶</a></h2>
<p>The <span class="math notranslate nohighlight">\(n \times n\)</span> Hilbert matrix <span class="math notranslate nohighlight">\(H_n\)</span> has elements</p>
<div class="math notranslate nohighlight">
\[H_{i, j} = \frac{1}{i+j-1}\]</div>
<p>Or if we index from zero in Pythonic fashion, the entries are <span class="math notranslate nohighlight">\(1/(1+i+j)\)</span></p>
<p>For example</p>
<div class="math notranslate nohighlight">
\[\begin{split}H_4 = \left[ \begin{array}{cccc} 1 &amp; 1/2 &amp; 1/3 &amp; 1/4 \\ 1/2 &amp; 1/3 &amp; 1/4 &amp; 1/5 \\1/3 &amp; 1/4 &amp; 1/5 &amp; 1/6 \\1/4 &amp; 1/5 &amp; 1/6 &amp; 1/7 \end{array} \right]\end{split}\]</div>
<p>and for larger or smaller <span class="math notranslate nohighlight">\(n\)</span>, one simply adds or remove rows below and columns at right.</p>
<p>Thee matrices arise in important situations like finding the polynomial of degree <span class="math notranslate nohighlight">\(n-1\)</span> that fits given data in the sense of minimizing the root-mean-square error — as we will discuss later in this course if there is time and interest.</p>
<p>Unfortunately as <span class="math notranslate nohighlight">\(n\)</span> increases the condition number grows rapidly, causing severe rounding error problems.
To illustrate this, I will do something that one should usually avoid: compute the inverse of these matrices.
This is also a case that shows th advatage of the LU factorization, since one compute thr inverse by succesively computing each column, by solving <span class="math notranslate nohighlight">\(n\)</span> different systems of equations, each with the same matrix <span class="math notranslate nohighlight">\(A\)</span> on the left-hand side.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">inf</span>
<span class="kn">from</span> <span class="nn">numerical_methods_module</span> <span class="kn">import</span> <span class="n">lu</span><span class="p">,</span> <span class="n">forwardSubstitution</span><span class="p">,</span> <span class="n">backwardSubstitution</span><span class="p">,</span> <span class="n">rowReduce</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">norm</span><span class="p">,</span> <span class="n">cond</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">random</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">inverse</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Use sparingly; there is usually a way to avoid computing inverses that is faster and with less rounding error!&quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">A_inverse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span> <span class="o">=</span> <span class="n">lu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">forwardSubstitution</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">A_inverse</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">backwardSubstitution</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">A_inverse</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hilbert</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">H</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="n">j</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">H</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">H_n</span> <span class="o">=</span> <span class="n">hilbert</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;H_</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> is&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">H_n</span><span class="p">)</span>
    <span class="n">H_n_inverse</span> <span class="o">=</span> <span class="n">inverse</span><span class="p">(</span><span class="n">H_n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;and its inverse is&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">H_n_inverse</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;to verify, their product is&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">H_n</span> <span class="o">@</span> <span class="n">H_n_inverse</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>H_2 is
[[1.         0.5       ]
 [0.5        0.33333333]]
and its inverse is
[[ 4. -6.]
 [-6. 12.]]
to verify, their product is
[[1. 0.]
 [0. 1.]]

H_3 is
[[1.         0.5        0.33333333]
 [0.5        0.33333333 0.25      ]
 [0.33333333 0.25       0.2       ]]
and its inverse is
[[   9.  -36.   30.]
 [ -36.  192. -180.]
 [  30. -180.  180.]]
to verify, their product is
[[ 1.00000000e+00  9.62193288e-16  1.40628250e-15]
 [ 0.00000000e+00  1.00000000e+00  0.00000000e+00]
 [-2.22044605e-17 -1.99840144e-15  1.00000000e+00]]

H_4 is
[[1.         0.5        0.33333333 0.25      ]
 [0.5        0.33333333 0.25       0.2       ]
 [0.33333333 0.25       0.2        0.16666667]
 [0.25       0.2        0.16666667 0.14285714]]
and its inverse is
[[   16.  -120.   240.  -140.]
 [ -120.  1200. -2700.  1680.]
 [  240. -2700.  6480. -4200.]
 [ -140.  1680. -4200.  2800.]]
to verify, their product is
[[ 1.00000000e+00  0.00000000e+00  4.54747351e-13 -2.27373675e-13]
 [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00]
 [-7.10542736e-15  0.00000000e+00  1.00000000e+00  0.00000000e+00]
 [ 0.00000000e+00 -5.68434189e-14  2.27373675e-13  1.00000000e+00]]
</pre></div>
</div>
</div>
</div>
<p>Note how the inverses have some surprisingly large elements; this is the matrix equivalent of a number being very close to zero and so with a very large reciprocal.</p>
<p>Since we have the inverses, we can compute the matrix norms of each <span class="math notranslate nohighlight">\(H_n\)</span> and its inverse, and thence their condition numbers; then this can be compared to the approximations of these condition numbers given by <code class="docutils literal notranslate"><span class="pre">numpy.linalg.cond</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">H_n</span> <span class="o">=</span> <span class="n">hilbert</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;H_</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> is&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">H_n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;with infinity norm </span><span class="si">{</span><span class="n">norm</span><span class="p">(</span><span class="n">H_n</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> 
    <span class="n">H_n_inverse</span> <span class="o">=</span> <span class="n">inverse</span><span class="p">(</span><span class="n">H_n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;and its inverse is&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">H_n_inverse</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;with infinity norm </span><span class="si">{</span><span class="n">norm</span><span class="p">(</span><span class="n">H_n_inverse</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> 
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Thus the condition number of H_</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="n">norm</span><span class="p">(</span><span class="n">H_n</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span> <span class="o">*</span> <span class="n">norm</span><span class="p">(</span><span class="n">H_n_inverse</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;For comparison, numpy.linalg.cond gives </span><span class="si">{</span><span class="n">cond</span><span class="p">(</span><span class="n">H_n</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>H_2 is
[[1.         0.5       ]
 [0.5        0.33333333]]
with infinity norm 1.5
and its inverse is
[[ 4. -6.]
 [-6. 12.]]
with infinity norm 18.000000000000007
Thus the condition number of H_2 is 27.00000000000001
For comparison, numpy.linalg.cond gives 27.00000000000001

H_3 is
[[1.         0.5        0.33333333]
 [0.5        0.33333333 0.25      ]
 [0.33333333 0.25       0.2       ]]
with infinity norm 1.8333333333333333
and its inverse is
[[   9.  -36.   30.]
 [ -36.  192. -180.]
 [  30. -180.  180.]]
with infinity norm 408.00000000000165
Thus the condition number of H_3 is 748.000000000003
For comparison, numpy.linalg.cond gives 748.0000000000028

H_4 is
[[1.         0.5        0.33333333 0.25      ]
 [0.5        0.33333333 0.25       0.2       ]
 [0.33333333 0.25       0.2        0.16666667]
 [0.25       0.2        0.16666667 0.14285714]]
with infinity norm 2.083333333333333
and its inverse is
[[   16.  -120.   240.  -140.]
 [ -120.  1200. -2700.  1680.]
 [  240. -2700.  6480. -4200.]
 [ -140.  1680. -4200.  2800.]]
with infinity norm 13619.999999996671
Thus the condition number of H_4 is 28374.999999993062
For comparison, numpy.linalg.cond gives 28374.99999999729

H_5 is
[[1.         0.5        0.33333333 0.25       0.2       ]
 [0.5        0.33333333 0.25       0.2        0.16666667]
 [0.33333333 0.25       0.2        0.16666667 0.14285714]
 [0.25       0.2        0.16666667 0.14285714 0.125     ]
 [0.2        0.16666667 0.14285714 0.125      0.11111111]]
with infinity norm 2.283333333333333
and its inverse is
[[ 2.500e+01 -3.000e+02  1.050e+03 -1.400e+03  6.300e+02]
 [-3.000e+02  4.800e+03 -1.890e+04  2.688e+04 -1.260e+04]
 [ 1.050e+03 -1.890e+04  7.938e+04 -1.176e+05  5.670e+04]
 [-1.400e+03  2.688e+04 -1.176e+05  1.792e+05 -8.820e+04]
 [ 6.300e+02 -1.260e+04  5.670e+04 -8.820e+04  4.410e+04]]
with infinity norm 413279.99999865814
Thus the condition number of H_5 is 943655.9999969361
For comparison, numpy.linalg.cond gives 943655.9999992514
</pre></div>
</div>
</div>
</div>
<p>Next, experiment with solving equations, to compare residuala with actual errors.</p>
<p>I will use the testing strategy of starting with a known solution <span class="math notranslate nohighlight">\(x\)</span>, from which the right-hand side <span class="math notranslate nohighlight">\(b\)</span> is computed;
then slight simulated error is introduced to <span class="math notranslate nohighlight">\(b\)</span>.
Rngin the os repeatedlt with use differnt random “errors”, to gin an ide of how the actual error</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">n</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">H_n</span> <span class="o">=</span> <span class="n">hilbert</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="c1">#x = np.zeros(n)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x is </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">H_n</span> <span class="o">@</span> <span class="n">x</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;b is </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">error_scale</span> <span class="o">=</span> <span class="mf">1e-8</span>
    <span class="n">b_imperfect</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">error_scale</span> <span class="o">*</span> <span class="p">(</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="c1"># add random &quot;errors&quot; between -error_scale and error_scale</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;b has been slightly changed to </span><span class="si">{</span><span class="n">b_imperfect</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">=</span> <span class="n">rowReduce</span><span class="p">(</span><span class="n">H_n</span><span class="p">,</span> <span class="n">b_imperfect</span><span class="p">)</span>
    <span class="n">x_computed</span> <span class="o">=</span> <span class="n">backwardSubstitution</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    <span class="n">residual</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">H_n</span> <span class="o">@</span> <span class="n">x_computed</span>
    <span class="n">relative_backward_error</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">residual</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span><span class="o">/</span><span class="n">norm</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The residual maximum norm is </span><span class="si">{</span><span class="n">norm</span><span class="p">(</span><span class="n">residual</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;and the relative backward error ||r||/||b|| is </span><span class="si">{</span><span class="n">relative_backward_error</span><span class="si">:</span><span class="s2">0.4</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">absolute_error</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_computed</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span>
    <span class="n">relative_error</span> <span class="o">=</span> <span class="n">absolute_error</span><span class="o">/</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The absolute error is </span><span class="si">{</span><span class="n">absolute_error</span><span class="si">:</span><span class="s2">0.4</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The relative error is </span><span class="si">{</span><span class="n">relative_error</span><span class="si">:</span><span class="s2">0.4</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">error_bound</span> <span class="o">=</span> <span class="n">cond</span><span class="p">(</span><span class="n">H_n</span><span class="p">,</span> <span class="n">inf</span><span class="p">)</span> <span class="o">*</span> <span class="n">relative_backward_error</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;For comparison, the relative error bound from the formula above is </span><span class="si">{</span><span class="n">error_bound</span><span class="si">:</span><span class="s2">0.4</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Beware: the relative error is larger than the relative backward error by a factor </span><span class="si">{</span><span class="n">relative_error</span><span class="o">/</span><span class="n">relative_backward_error</span><span class="si">:</span><span class="s2">0.8</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>n=2
x is [1. 2.]
b is [2.         1.16666667]
b has been slightly changed to [2.00000001 1.16666667]
The residual maximum norm is 6.413956921136332e-09
and the relative backward error ||r||/||b|| is 3.207e-09
The absolute error is 6.335e-09
The relative error is 3.167e-09
For comparison, the relative error bound from the formula above is 8.659e-08

Beware: the relative error is larger than the relative backward error by a factor 0.98764383

n=3
x is [1. 2. 3.]
b is [3.         1.91666667 1.43333333]
b has been slightly changed to [2.99999999 1.91666667 1.43333333]
The residual maximum norm is 7.406832036593869e-09
and the relative backward error ||r||/||b|| is 2.469e-09
The absolute error is 1.287e-06
The relative error is 4.289e-07
For comparison, the relative error bound from the formula above is 1.847e-06

Beware: the relative error is larger than the relative backward error by a factor 173.72107

n=4
x is [1. 2. 3. 4.]
b is [4.         2.71666667 2.1        1.72142857]
b has been slightly changed to [4.         2.71666668 2.10000001 1.72142857]
The residual maximum norm is 9.815670942714405e-09
and the relative backward error ||r||/||b|| is 2.454e-09
The absolute error is 3.499e-05
The relative error is 8.748e-06
For comparison, the relative error bound from the formula above is 6.963e-05

Beware: the relative error is larger than the relative backward error by a factor 3564.9129

n=5
x is [1. 2. 3. 4. 5.]
b is [5.         3.55       2.81428571 2.34642857 2.01746032]
b has been slightly changed to [5.         3.55       2.81428572 2.34642857 2.01746031]
The residual maximum norm is 5.082728016247984e-09
and the relative backward error ||r||/||b|| is 1.017e-09
The absolute error is 0.000315
The relative error is 6.3e-05
For comparison, the relative error bound from the formula above is 0.0009593

Beware: the relative error is larger than the relative backward error by a factor 61972.109
</pre></div>
</div>
</div>
</div>
<p>We see in these experiments that:</p>
<ul class="simple">
<li><p>As the condition number increases, the relative error becomes increasingly larger than the backward error computed from the residual.</p></li>
<li><p>It is less than the above bound
<span class="math notranslate nohighlight">\(\displaystyle \text{Rel}(x_a) = \frac{\|x - x_a\|}{\| x \|} \leq \kappa(A) \frac{\|r\|}{\|b\|},\)</span>
and typically quite a bit less.</p></li>
</ul>
<hr class="docutils" />
<p>This work is licensed under <a class="reference external" href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International</a></p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ODE-IVP-5-error-control-python.html" title="previous page"><span class="section-number">25. </span>Initial Value Problems for Ordinary Differential Equations, Part 5: Error Control and Variable Step Sizes</a>
    <a class='right-next' id="next-link" href="simultaneous-linear-equations-6-iterative-methods.html" title="next page"><span class="section-number">27. </span>Simultaneous Linear Equations, Part 6: Iterative Methods</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Brenton LeMesurier, College of Charleston and University of Northern Colorado<br/>
        
            &copy; Copyright 2020–2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>