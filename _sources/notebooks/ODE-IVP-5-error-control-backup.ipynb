{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Value Problems for Ordinary Differential Equations, Part 5: Error Control and Variable Step Sizes — Preliminary Version\n",
    "\n",
    "**Version of April 5, 2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "- Section 6.5 *Variable Step Size Methods* of [Sauer](../references.html#Sauer)\n",
    "\n",
    "- Section 5.5 *Error Control and the Runge-Kutta-Fehlberg Method* of [Burden&Faires](../references.html#Burden-Faires)\n",
    "\n",
    "- Section  7.3 of [Chenney&Kincaid](../references.html#Chenney-Kincaid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basic ODE Initial Value Problem\n",
    "\n",
    "We consider again the initial value problem\n",
    "\n",
    "$$\n",
    "\\frac{d u}{d t} = f(t, u) \\quad a \\leq t \\leq b, \\quad u(a) = u_0\n",
    "$$\n",
    "\n",
    "We now allow the possibility that $u$ and $f$ are vector-valued as in the section on\n",
    "[Systems of ODEs and Higher Order ODEs](ODE-IVP-4-system-higher-order-equations.ipynb),\n",
    "but omitting the tilde notation $\\tilde u$, $\\tilde f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Control by Varying the Time Step Size $h_i$\n",
    "\n",
    "Recall the variable step-size version of Euler's method:\n",
    "\n",
    "Input: $f$, $a$, $b$, $n$ <br>\n",
    "\n",
    "$t_0 = a$ <br>\n",
    "$U_0 = u_0$ <br>\n",
    "$h = (b-a)/n$ <br>\n",
    "\n",
    "for i in $[0, n)$:\n",
    "<br>\n",
    "\n",
    "$\\qquad$ Choose step size $h_i$ somehow!\n",
    "<br>\n",
    "\n",
    "$\\qquad$ $t_{i+1} = t_i + h_i$\n",
    "<br>\n",
    "\n",
    "$\\qquad$ $U_{i+1} = U_i + h_i f(t_i, U_i)$\n",
    "<br>\n",
    "\n",
    "end for\n",
    "\n",
    "We now consider how to choose each step size, by estimating the error in each step, and aiming to have error per unit time below some limit like $\\epsilon/(b-a)$, so that the global error is no more than about $\\epsilon$.\n",
    "\n",
    "As usual, the theoretical error bounds like $O(h_i^2)$ for a single step of Euler's method are not enough for quantitative tasks like choosing $h_i$, but they do motivate more practical estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A crude error estimator for Euler's Method: Richardson Extrapolation\n",
    "\n",
    "Starting at a point (t, u(t)), we can estimate the error in Euler's method approximato at a slightly later time $t_i + h$ by using two approximations of $U(t + h)$:\n",
    "- The value given by a step of Euler's method with step size $h$: call this $U^{h}$\n",
    "- The value given by taking two steps of Euler's method each with step size $h/2$: call this $U_2^{h/2}$,\n",
    "because it involves 2 steps of size $h/2$.\n",
    "\n",
    "The first order accuracy of Euler's method gives $e_h := u(t+h) - U^{h} \\approx 2(u(t+h) - U_2^{h/2})$,\n",
    "so that\n",
    "\n",
    "$$e_h \\approx \\frac{U_2^{h/2} - U^{h}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step size choice\n",
    "\n",
    "What do we do with this error information?\n",
    "\n",
    "The first obvious ideas are:\n",
    "- Accept this step if $e_h$ is small enough, taking $h_i = h$, $t_{i+1} = t_i + h_i$, and $U_{i+1} = U^h$, but\n",
    "- reject it and try again with a smaller $h$ value otherwise; maybe halving $h$; but there are more sophisticated options too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a formula for $U_h$ and $e_h$ if one starts from the point $(t_i, U_i)$, so that $(t_i + h, U^h)$ is the proposed value for the next point $(t_{i+1}, U_{i+1})$ in the approximate solution — but only if $e_h$ is small enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error tolerance \n",
    "\n",
    "One simple criterion for accuracy is that the estimated error in this step be no more than some overall upper limit on the error in ech time step, $\\epsilon$.\n",
    "That is, accept the step size $h$ if\n",
    "\n",
    "$$|e_h| \\leq \\epsilon.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A crude approach to reducing the step size when needed\n",
    "\n",
    "If this error tolerance is not met, we must choose a new step size $h'$, and we can predict roughly its error behavior using the known order natue of the error in Euler's method: scaling dowen to $h' = s h$, the error in a step scales with $h^2$, so the error per unit time scales with $h$ (in general it scales with $h^p$ for a method of order $p$), and so to reduce the error by the needed factor $\\displaystyle \\frac{e_h/h}{\\epsilon}$ one needs approximately\n",
    "\n",
    "$$\n",
    "s = \\frac{\\epsilon}{|e_h|/h} = \\frac{h \\epsilon}{|e_h|}\n",
    "$$\n",
    "\n",
    "and so using $e_h \\approx |U^{h/2} - U^{h}|$ suggests using\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "s &= \\frac{h \\epsilon}{|U^{h/2} - U^{h}|}\n",
    "\\\\\n",
    "h' &= sh = \\frac{2 h^2 \\epsilon}{|U^{h/2} - U^{h}|}.\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "However this new step size might have error that is still slightly too large, leading to a second failure.\n",
    "Another is that one might get into an infinite loop of step size reduction.\n",
    "\n",
    "So refinements of this choice must be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing the step size when desirable\n",
    "\n",
    "If we simply follow the above aproach, the step size, once reduced, will never be increased.\n",
    "This could lead to great inefficiency, through using an unecessarily small step size just because at an earlier part of the time domain, accuracy required very small steps.\n",
    "\n",
    "Thus, after a successful time step, one might consider increasing $h$ for the next step.\n",
    "This could be done using exactly the above formula, but again there are risks, so again refinement of this choice must be considered.\n",
    "\n",
    "One problem is that if the step size gets too large, the error estimate can become unreliable; another is that one might need some minimum \"temporal resolution\", for nice graphs and such.\n",
    "\n",
    "Both suggest imposing an upper limit on the step size $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another strategy for getting error estimates: two (related) methods\n",
    "\n",
    "The recurring strategy of estimating errors by the difference of two different approximations — one expected to be far better than the other — can be used in a nice way here.\n",
    "I iwl ilusrat frst with the smplset version, using Euler's Matha dnt explicit Trapezoid Method.\n",
    "\n",
    "Revsl th the increment in Euler's Method from time $t$ to time $t+h$ is\n",
    "\n",
    "$$K_1 = h f(t, u)$$\n",
    "\n",
    "whereas for the explict trapezoid method it is $(K_1 + K_2)/2$, as given by\n",
    "\n",
    "$$\\begin{split}\n",
    "K_1 &= h f(t_i, U_i)\n",
    "\\\\\n",
    "K_2 &= h f(t_{i+1}, U_i + K_1)\n",
    "\\end{split}$$\n",
    "\n",
    "Thus we can use the difference, $|K_1 - (K_1 + K_2)/2| = |(K_1 - K_2)/2|$ as an error estimate.\n",
    "In fact to be cautious, one often drops the factor of $1/2$, so using $e_h \\approx |K_1 - K_2|$.\n",
    "\n",
    "One has to be careful: this estimates the error in Euler's Method, so one has to use it that way: using the less accurate value $K_1$ as the update.\n",
    "\n",
    "One basic algorithm for the time step starting with $t_i, U_i$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K_1 \\leftarrow h f(t_i, U_i)$\n",
    "\n",
    "$K_2 \\leftarrow f(t_{i+1}, U_i + K_1)$\n",
    "\n",
    "$e_{h} \\leftarrow |K_1 - K_2|$\n",
    "\n",
    "$s \\leftarrow (h \\epsilon)/e_h$\n",
    "\n",
    "if $s>1$: $\\qquad$ (I.e.  $e_h/h < \\epsilon$ and so good enough)\n",
    "\n",
    "$\\quad U_{i+1} = U_i + K_1$\n",
    "\n",
    "$\\quad t_{i+1} = t_i + h$\n",
    "\n",
    "$\\quad$ Increase $h$ for the *next* time step:\n",
    "\n",
    "$\\quad h \\leftarrow s h$\n",
    "\n",
    "else: $\\qquad$ ($s \\leq 1$, so not good enough: reduce $h$ and try again)\n",
    "\n",
    "$\\quad h \\leftarrow s h$\n",
    "\n",
    "$\\quad$ Start again from $K_1 = \\dots$\n",
    "\n",
    "end if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in practice one needs:\n",
    "\n",
    "- An upper limit $h_{max}$ on the step size $h$, partly becuase eror estimates are unreliable if $h$ is too large,\n",
    "and subsequent use of the results (like graphs) might need sufficiently \"fine\" data.\n",
    "\n",
    "- A lower limit $h_{max}$ on $h$, to avoid infinite loops and such.\n",
    "\n",
    "Incorporating these refinements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K_1 \\leftarrow h f(t_i, U_i)$\n",
    "\n",
    "$K_2 \\leftarrow f(t_{i+1}, U_i + K_1)$\n",
    "\n",
    "$e_{h} \\leftarrow |K_1 - K_2|$\n",
    "\n",
    "$s = \\epsilon/(e_h/h)$\n",
    "\n",
    "if $s>1$: $\\qquad$ (I.e.  $e_h/h < \\epsilon$ and so good enough)\n",
    "\n",
    "$\\quad U_{i+1} = U_i + K_1$\n",
    "\n",
    "$\\quad t_{i+1} = t_i + h$\n",
    "\n",
    "$\\quad$ Increase $h$ for the *next* time step:\n",
    "\n",
    "$\\quad h \\leftarrow \\min(s h, h_{max})$\n",
    "\n",
    "else: $\\qquad$ ($s \\leq 1$, so not good enough; reduce $h$ and try again)\n",
    "\n",
    "$\\quad h \\leftarrow \\max(s h, h_{min})$\n",
    "\n",
    "$\\quad$ Start again from $K_1 = \\dots$\n",
    "\n",
    "end if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Implement the above, and test on the two familiar examples\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "du/dt &= Ku\n",
    "\\\\\n",
    "&\\text{and}\n",
    "\\\\\n",
    "du/dt &= K(\\cos(t) - u) - \\sin(t)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "($K=1$ is enough.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Order Accurate Methods with Error Control\n",
    "\n",
    "In practice, one usually needs at least second order accuracy, and one approach to that is using computing a \"candidates\" for teh next time step with a second order accurate Runge-Kutta method and also a third order accurate one, the latter used only to get an error estimate for the former.\n",
    "\n",
    "Perhaps the simplest of these is based on adding error estimation to the Explicit Trapezoid Rule;\n",
    "omitting the step sze adjustment for now, the main ingredients are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K_1 = h f(t_i, U_i)$\n",
    "\n",
    "$K_2 = f(t_i + h, U_i + K_1)$\n",
    "\n",
    "(So far, as for the explicit trapezoid method)\n",
    "\n",
    "$K_3 = f(t_i + h/2, U_i + (K_1+K_2)/2)$\n",
    "\n",
    "$\\delta_2 = (K_1 + K_2)/2$\n",
    "(The order 2 increment as for the explicit trapezoid method)\n",
    "\n",
    "$\\delta_3 = (K_1 + 4 K_3 + K_2)/6$\n",
    "(An order 3 increment — note the resemblance to Simpson's Method)\n",
    "\n",
    "$e_h = |\\delta_2 - \\delta_3 |, \\, = (K_1 -2 K_3 + K_2)/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if this step is accepted, one uses the explicit trapezoid rule step: $U_{i+1} = U_i + \\delta_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step size adjustment\n",
    "\n",
    "The scale factor $s$ for step size adjustment is a bit different; for a method order $p$ (so $p=2$ now)\n",
    "changing step size by a factor $s$ will change the error $e_h$ in a single time step by a factor of about $s^{p+1}$.\n",
    "\n",
    "Thus, we want a new step with this rescaled error of about $s^{p+1} e_h$ roughly matching the tolerance $\\epsilon$.\n",
    "Equating would give $s^{p+1} e_h/h = \\epsilon$ so that $ = (\\epsilon/(e_h/h))^{1/(p+1)}$\n",
    "\n",
    "$$s = (\\epsilon/(e_h/h))^{1/p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Order Accurate Methods with Error Control: Runge-Kutta-Felberg and Some Newer Refinements\n",
    "\n",
    "The details involve some messy coefficients; see the references above for those.\n",
    "\n",
    "The basic idea is that ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
