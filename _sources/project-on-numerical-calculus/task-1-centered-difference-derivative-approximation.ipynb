{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caroline-baltimore",
   "metadata": {},
   "source": [
    "# Centered Difference Approximation of the Derivative\n",
    "\n",
    "**Revised March 22, 25 and 26,** adding a mathematical exercise, more details and an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-print",
   "metadata": {},
   "source": [
    "## Programming Exercise\n",
    "\n",
    "Write a (Python) function to approximate derivatives using the centered difference formula,\n",
    "\n",
    "$$\n",
    "Df(x) \\approx \\delta_hf(x) := \\frac{f(x+h) - f(x-h)}{2h}\n",
    "$$\n",
    "\n",
    "The input variables should include the node spacing $h$; think about and discuss what all the input and output variables should be.\n",
    "(Also, remember that such a function should not do any interactive input, or any output to the screen or files.)\n",
    "\n",
    "Then — as usual — add code that tests this on some examples such as $f(x) = e^x$, $f'(1)$ as suggested in the section on [Test Cases for Differentiation](test-cases-differentiation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-monkey",
   "metadata": {},
   "source": [
    "**Note:** For the above function and every function below, create a Jupyter notebook to run test cases: this will handle any interactive input and any screen or file output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-shadow",
   "metadata": {},
   "source": [
    "### Warm-up exercise: forward difference aproximation\n",
    "\n",
    "Let us do this for the forward difference approximation\n",
    "\n",
    "$$\n",
    "Df(x) \\approx D_h(x) := \\frac{f(x+h) - f(x)}{h}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "renewable-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hired-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_h(f, x, h):\n",
    "    D_h_of_f_at_x = (f(x+h) - f(x))/h\n",
    "    return D_h_of_f_at_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stunning-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "further-count",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For x=0.0:\n",
      "For h=0.1:\n",
      "D_hf=1.0517091807564771\n",
      "error=0.051709180756477124\n",
      "For h=0.01:\n",
      "D_hf=1.005016708416795\n",
      "error=0.005016708416794913\n",
      "For h=0.001:\n",
      "D_hf=1.0005001667083846\n",
      "error=0.0005001667083845973\n",
      "For x=1.0:\n",
      "For h=0.1:\n",
      "D_hf=2.858841954873883\n",
      "error=0.14056012641483795\n",
      "For h=0.01:\n",
      "D_hf=2.7319186557871245\n",
      "error=0.01363682732807936\n",
      "For h=0.001:\n",
      "D_hf=2.7196414225332255\n",
      "error=0.0013595940741804036\n",
      "For x=3.0:\n",
      "For h=0.1:\n",
      "D_hf=21.12414358253968\n",
      "error=1.0386066593520127\n",
      "For h=0.01:\n",
      "D_hf=20.186300205325836\n",
      "error=0.10076328213816765\n",
      "For h=0.001:\n",
      "D_hf=20.095583040074416\n",
      "error=0.01004611688674828\n"
     ]
    }
   ],
   "source": [
    "x = 1.\n",
    "#h = 0.01\n",
    "for x in [0., 1., 3.]:\n",
    "    print(f\"For {x=}:\")\n",
    "    for h in [0.1, 0.01, 0.001]:\n",
    "        print(f\"For {h=}:\")\n",
    "        D_hf = D_h(f, x, h)\n",
    "        print(f\"{D_hf=}\")\n",
    "        Df_exact = f(x)\n",
    "        error = D_hf - Df_exact\n",
    "        print(f\"{error=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-treasurer",
   "metadata": {},
   "source": [
    "## Mathematical Exercise\n",
    "\n",
    "Verify the order of accuracy result\n",
    "\n",
    "$$\n",
    "Df(x) - \\delta_hf(x) = O(h^2)\n",
    "$$\n",
    "\n",
    "and the (equivalent) fact that this method has degree of precision 2: it is exact fo all quadratics.\n",
    "\n",
    "One could in fact go further and derive the error formula\n",
    "\n",
    "$$\n",
    "Df(x) - \\delta_hf(x) = -\\frac{D^3f(\\xi)}{6} h^2,\\quad\\text{for some } \\xi \\in (x-h, x+h)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
