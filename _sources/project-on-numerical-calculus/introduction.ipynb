{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "============\n",
    "\n",
    "This project will combine and explore methods for approximation of derivatives and integrals, along with methods for estimating errors and *using these error estimates to improve accuracy.*\n",
    "\n",
    "We will also compare the performance of various methods: this is often important in making the choice of algorithms for a larger task.\n",
    "\n",
    "In part, this is an exercise in *good written presentation of mathematical and computational results*, and as preparation for the second individual project that each of you will do at the end of the semester.\n",
    "The \"introduction\" and \"methods\" sections specified below can be quite brief in this project (as many details are specified below) but will be more significant in your final project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New Due Date for Final Versions: Friday April 9**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some General Advice (updated on April 5)\n",
    "\n",
    "A) Always put your **name** and the **current** version date near the top: see above!\n",
    "\n",
    "B) When possible, start with test cases for which you know the exact result, and then check the actual errors and include those in the output. (This is mostly relevant to learning about an algorithm and developing code for it.)\n",
    "\n",
    "C) Initially use the test cases given in\n",
    "[Test Cases for Differentiation](test-cases-differentiation)\n",
    "and\n",
    "[Test Cases for Integration](test-cases-integration);\n",
    "then choose and explore some others.\n",
    "\n",
    "D) When instead you can get an error estimate, compute that and include it in the output. (This is far more relevant to \"real-world\" use of an algorithm.)\n",
    "\n",
    "Note: For a great many methods, there is a useful general strategy for getting error estimates:\n",
    "    1. get two approximations where you have good reason to believe that one is at least about twice as accuarate as the other.\n",
    "    2. Use the difference to estimat the error in th **less** accurate of the two approximations â€” this is the \"pessimistic\" approach recommended above.\n",
    "\n",
    "For example with errors $O(h^p)$, $p \\geq 1$, one can use results for $h$ and $h/2$ to estimate the error in the first of these;\n",
    "likewise with errors $O(1/n^p)$, use the approximations for $n$ and $2n$ to estimate the error in the former.\n",
    "\n",
    "E) While testing and demonstrating an iterative method, have a \"demonstration\" or \"testing\" mode which gives the option of displaying actual errors and or error estimates *at each iteration*, to illustrate convergence.\n",
    "\n",
    "F) In general (but not absolutely always), aim to make functions \"self-contained\":\n",
    "        - getting all the information they need via input parameters, and\n",
    "        - delivering all results through `return` statements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
