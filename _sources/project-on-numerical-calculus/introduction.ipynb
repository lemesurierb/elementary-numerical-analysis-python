{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "============\n",
    "\n",
    "This project will combine and explore methods for approximation of derivatives and integrals, along with methods for estimating errors and *using these error estimates to improve accuracy.*\n",
    "\n",
    "We will also compare the performance of various methods: this is often important in making the choice of algorithms for a larger task.\n",
    "\n",
    "In part, this is an exercise in *good written presentation of mathematical and computational results*, and as preparation for the second individual project that each of you will do at the end of the semester.\n",
    "The \"introduction\" and \"methods\" sections specified below can be quite brief in this project (as many details are specified below) but will be more significant in your final project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New Due Date for Final Versions: Friday April 9**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some General Advice\n",
    "\n",
    "I will add here some general tips and reminders about working on projects and more generaly on working with numerical methods;\n",
    "some that come out of discussing draft work with you.\n",
    "For now just these:\n",
    "\n",
    "A) For every approximate numerical value computed, strive to get some information about its acccuracy:\n",
    "\n",
    "- An **error bound** is best, though often not available.\n",
    "\n",
    "- An **error estimate** is next best;\n",
    "    these should err towards \"pessimism\" — usually overestimating the error;\n",
    "\n",
    "- in cases where you have neither of the above in general, test on some special cases for which you can get the exact result by another method, and use that to give the **actual error** for such test cases.\n",
    "\n",
    "B) For a great many methods, there is a useful general strategy for getting error estimates:\n",
    "    1. get two approximations where you have good reason to believe that one is at least about twice as accuarate as the other.\n",
    "    2. Use the difference to estimat the error in th **less** accurate of the two approximations — this is the \"pessimistic\" approach recommended above.\n",
    "\n",
    "For example with errors $O(h^p)$, $p \\geq 1$, one can use results for $h$ and $h/2$ to estimate the error in the first of these;\n",
    "likewise with errors $O(1/n^p)$, use the approximations for $n$ and $2n$ to estimate the error in the former.\n",
    "(We will soon see a variant for ODEs.)\n",
    "\n",
    "C) Initially use the test cases given in\n",
    "[Test Cases for Differentiation](test-cases-differentiation)\n",
    "and\n",
    "[Test Cases for Integration](test-cases-integration);\n",
    "then choose and explore some others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
